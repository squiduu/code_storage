{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from iterate_data import get_dataloader_and_text\n",
    "import torch\n",
    "\n",
    "\n",
    "def highlight(word, attn):\n",
    "    \"\"\"the higher attention value, the stronger red background of text\"\"\"\n",
    "\n",
    "    html_color = \"#%02X%02X%02X\" % (255, int(255 * (1 - attn)), int(255 * (1 - attn)))\n",
    "\n",
    "    return f'<span style=\"background-color: {html_color}\"> {word}</span>'\n",
    "\n",
    "\n",
    "def make_html(index, batch, preds, normalized_weights_1, normalized_weights_2, TEXT):\n",
    "    \"\"\"make html data\"\"\"\n",
    "\n",
    "    # get index result of sentences, labels, and preds\n",
    "    sentence = batch.Text[0][index]\n",
    "    label = batch.Label[index]\n",
    "    pred = preds[index]\n",
    "\n",
    "    # get and normalize attention values of index\n",
    "    attns_1 = normalized_weights_1[index, 0, :]\n",
    "    attns_1 /= attns_1.max()\n",
    "\n",
    "    attns_2 = normalized_weights_2[index, 0, :]\n",
    "    attns_2 /= attns_2.max()\n",
    "\n",
    "    # replace labels and predictions to word\n",
    "    if label == 0:\n",
    "        label_str = \"Negative\"\n",
    "    else:\n",
    "        label_str = \"Positive\"\n",
    "\n",
    "    if pred == 0:\n",
    "        pred_str = \"Negative\"\n",
    "    else:\n",
    "        pred_str = \"Positive\"\n",
    "\n",
    "    # make html data to show\n",
    "    html = f\"Correct labels: {label_str}<br>Inference labels: {pred_str}<br><br>\"\n",
    "\n",
    "    # get attentions of the first transformer block\n",
    "    html += \"[Visualization attentions of the first transformer block]<br>\"\n",
    "    for word, attn in zip(sentence, attns_1):\n",
    "        html += highlight(TEXT.vocab.itos[word], attn)\n",
    "    html += \"<br><br>\"\n",
    "\n",
    "    # get attentions of the second transformer block\n",
    "    html += \"[Visualization attentions of the first transformer block]<br>\"\n",
    "    for word, attn in zip(sentence, attns_2):\n",
    "        html += highlight(TEXT.vocab.itos[word], attn)\n",
    "    html += \"<br><br>\"\n",
    "\n",
    "    return html\n",
    "\n",
    "\n",
    "# set batch size\n",
    "batch_size = 128\n",
    "# get dataloader\n",
    "train_dl, val_dl, test_dl, TEXT = get_dataloader_and_text(\n",
    "    max_length=256, batch_size=batch_size\n",
    ")\n",
    "# get mini-batch from dataloader\n",
    "batch = next(iter(test_dl))\n",
    "\n",
    "# set GPU environment\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# set input text and labels to GPU environment\n",
    "# Text and Label are field name of dataloader\n",
    "inp_text = batch.Text[0].to(device)\n",
    "labels = batch.Label.to(device)\n",
    "\n",
    "# special token '<pad>' equals 1 in vocab ID\n",
    "# set attention padding mask with '<pad>'\n",
    "inp_mask = inp_text != 1\n",
    "\n",
    "# set path of trained models\n",
    "PATH = \"./checkpoints/\"\n",
    "# load trained model\n",
    "net_trained = torch.load(f=PATH + f\"batchsize_{batch_size}/model_ep10_acc0.8550.pt\")\n",
    "# set evaluation mode\n",
    "net_trained.eval()\n",
    "# set trained model to GPU environment\n",
    "net_trained = net_trained.to(device)\n",
    "\n",
    "# get the final classification results\n",
    "y, normalized_weights_1, normalized_weights_2 = net_trained(inp_text, inp_mask)\n",
    "# predict labels with row: 0 or 1\n",
    "_, preds = torch.max(y, dim=1)\n",
    "\n",
    "# get data to show\n",
    "index = 3\n",
    "# make html\n",
    "html_outp = make_html(\n",
    "    index=index,\n",
    "    batch=batch,\n",
    "    preds=preds,\n",
    "    normalized_weights_1=normalized_weights_1,\n",
    "    normalized_weights_2=normalized_weights_2,\n",
    "    TEXT=TEXT,\n",
    ")\n",
    "# visualize html result\n",
    "HTML(html_outp)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
